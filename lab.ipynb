{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_classifier import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config_file = 'model/uncased_L-12_H-768_A-12/bert_config.json'\n",
    "train_tfrecord_fpath = '/tmp/mrpc_output/train.tf_record'\n",
    "is_training = True\n",
    "batch_size = 32\n",
    "seq_length = 128\n",
    "num_labels = 2\n",
    "use_one_hot_embeddings = False\n",
    "init_checkpoint = 'model/uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n",
    "#bert_config.hidden_dropout_prob = 0.0\n",
    "#bert_config.attention_probs_dropout_prob = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(train_tfrecord_fpath):\n",
    "    name_to_features = {\n",
    "                \"input_ids_1\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "                \"input_ids_2\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "                \"input_mask_1\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "                \"input_mask_2\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "                \"label_ids\": tf.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "\n",
    "    def _decode_record(record, name_to_features):\n",
    "        \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "        example = tf.parse_single_example(record, name_to_features)\n",
    "\n",
    "        # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "        # So cast all int64 to int32.\n",
    "        for name in list(example.keys()):\n",
    "            t = example[name]\n",
    "            if t.dtype == tf.int64:\n",
    "                t = tf.to_int32(t)\n",
    "            example[name] = t\n",
    "\n",
    "        return example\n",
    "\n",
    "    d = tf.data.TFRecordDataset(train_tfrecord_fpath)\n",
    "\n",
    "    d = d.apply(\n",
    "            tf.contrib.data.map_and_batch(\n",
    "                    lambda record: _decode_record(record, name_to_features),\n",
    "                    batch_size=batch_size\n",
    "            ))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_file(tfrecord_fpath):\n",
    "    d = get_dataset(tfrecord_fpath)\n",
    "    handle = tf.placeholder(tf.string, shape=[])\n",
    "    iterator = tf.data.Iterator.from_string_handle(handle, d.output_types, d.output_shapes)\n",
    "    input_tensors = iterator.get_next()\n",
    "    \n",
    "    return handle, d.make_one_shot_iterator().string_handle(), input_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input_tensors(input_tensors):\n",
    "    input_ids = [input_tensors['input_ids_1'], input_tensors['input_ids_2']]\n",
    "    input_mask = [input_tensors['input_mask_1'], input_tensors['input_mask_2']]\n",
    "    segment_ids = None\n",
    "    label_ids = input_tensors['label_ids']\n",
    "    return input_ids, input_mask, segment_ids, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle, batch_iter, input_tensors = read_from_file(train_tfrecord_fpath)\n",
    "input_ids, input_mask, segment_ids, label_ids = parse_input_tensors(input_tensors)\n",
    "\n",
    "models = []\n",
    "for i in range(2):\n",
    "    model = modeling.BertModel(\n",
    "                config=bert_config,\n",
    "                is_training=is_training,\n",
    "                input_ids=input_ids[i],\n",
    "                input_mask=input_mask[i],\n",
    "                token_type_ids=segment_ids,\n",
    "                use_one_hot_embeddings=use_one_hot_embeddings)\n",
    "    \n",
    "    models.append(model)\n",
    "    \n",
    "hidden_size = models[0].get_pooled_output().shape[-1].value\n",
    "sentence_distance = tf.exp(models[0].pooled_output-models[1].pooled_output)\n",
    "output_weights = tf.get_variable(\n",
    "        \"output_weights\", [num_labels, hidden_size],\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "output_bias = tf.get_variable(\n",
    "        \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "with tf.variable_scope(\"loss\"):\n",
    "    if is_training:\n",
    "        # I.e., 0.1 dropout\n",
    "        output_layer = tf.nn.dropout(sentence_distance, keep_prob=0.9)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    one_hot_labels = tf.one_hot(label_ids, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    \n",
    "classificatoin_layer_vars = [output_weights, output_bias]\n",
    "global_step = tf.Variable(0)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss, var_list=classificatoin_layer_vars, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    bert_vars = [var for var in tf.global_variables() if var.name.startswith('bert')]\n",
    "    saver = tf.train.Saver(bert_vars)\n",
    "    saver.restore(sess, init_checkpoint)\n",
    "    \n",
    "    batch = sess.run(batch_iter)\n",
    "    \n",
    "    for step in range(100):\n",
    "        out = sess.run([train_op, loss, global_step], feed_dict={handle: batch})\n",
    "        print(step, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
