{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_classifier import *\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config_file = 'model/uncased_L-12_H-768_A-12/bert_config.json'\n",
    "train_tfrecord_fpath = '/tmp/mrpc_output/train.tf_record'\n",
    "eval_tfrecord_fpath = '/tmp/mrpc_output/eval.tf_record'\n",
    "is_training = True\n",
    "batch_size = 32\n",
    "epoch_batch_num = 100/batch_size\n",
    "seq_length = 128\n",
    "num_labels = 2\n",
    "use_one_hot_embeddings = False\n",
    "init_checkpoint = 'model/uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
    "learning_rate = 5e-5\n",
    "num_train_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n",
    "#bert_config.hidden_dropout_prob = 0.0\n",
    "#bert_config.attention_probs_dropout_prob = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(train_tfrecord_fpath, is_train):\n",
    "    name_to_features = {\n",
    "                \"input_ids_1\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "                \"input_ids_2\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "                \"input_mask_1\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "                \"input_mask_2\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "                \"label_ids\": tf.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "\n",
    "    def _decode_record(record, name_to_features):\n",
    "        \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "        example = tf.parse_single_example(record, name_to_features)\n",
    "\n",
    "        # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "        # So cast all int64 to int32.\n",
    "        for name in list(example.keys()):\n",
    "            t = example[name]\n",
    "            if t.dtype == tf.int64:\n",
    "                t = tf.to_int32(t)\n",
    "            example[name] = t\n",
    "\n",
    "        return example\n",
    "\n",
    "    d = tf.data.TFRecordDataset(train_tfrecord_fpath)\n",
    "    if is_train:\n",
    "        d = d.repeat()\n",
    "        d = d.shuffle(buffer_size=100)\n",
    "\n",
    "    d = d.apply(\n",
    "            tf.contrib.data.map_and_batch(\n",
    "                    lambda record: _decode_record(record, name_to_features),\n",
    "                    batch_size=batch_size\n",
    "            ))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_file(tfrecord_fpath, is_train=False):\n",
    "    d = get_dataset(tfrecord_fpath, is_train)\n",
    "    handle = tf.placeholder(tf.string, shape=[])\n",
    "    iterator = tf.data.Iterator.from_string_handle(handle, d.output_types, d.output_shapes)\n",
    "    input_tensors = iterator.get_next()\n",
    "    \n",
    "    return handle, d.make_one_shot_iterator().string_handle(), input_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input_tensors(input_tensors):\n",
    "    input_ids = [input_tensors['input_ids_1'], input_tensors['input_ids_2']]\n",
    "    input_mask = [input_tensors['input_mask_1'], input_tensors['input_mask_2']]\n",
    "    segment_ids = None\n",
    "    label_ids = input_tensors['label_ids']\n",
    "    return input_ids, input_mask, segment_ids, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(accuracy, feed_dict, sess, steps):\n",
    "    acc = []\n",
    "    for step in range(int(steps)):\n",
    "        out = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        acc.append(out[0])\n",
    "\n",
    "    return np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "handle, train_batch_iter, input_tensors = read_from_file(train_tfrecord_fpath, is_train=True)\n",
    "_, eval_batch_iter, _ = read_from_file(eval_tfrecord_fpath, is_train=True)\n",
    "input_ids, input_mask, segment_ids, label_ids = parse_input_tensors(input_tensors)\n",
    "\n",
    "models = []\n",
    "for i in range(2):\n",
    "    model = modeling.BertModel(\n",
    "                config=bert_config,\n",
    "                is_training=is_training,\n",
    "                input_ids=input_ids[i],\n",
    "                input_mask=input_mask[i],\n",
    "                token_type_ids=segment_ids,\n",
    "                use_one_hot_embeddings=use_one_hot_embeddings)\n",
    "    \n",
    "    models.append(model)\n",
    "\n",
    "hidden_size = models[0].get_pooled_output().shape[-1].value\n",
    "sentence_distance = tf.squared_difference(models[0].pooled_output, models[1].pooled_output)\n",
    "output_weights = tf.get_variable(\n",
    "        \"output_weights\", [num_labels, hidden_size],\n",
    "        initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "output_bias = tf.get_variable(\n",
    "        \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "dropout_keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "with tf.variable_scope(\"loss\"):\n",
    "    if is_training:\n",
    "        # I.e., 0.1 dropout\n",
    "        output_layer = tf.nn.dropout(sentence_distance, keep_prob=dropout_keep_prob)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "    predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "\n",
    "    one_hot_labels = tf.one_hot(label_ids, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    \n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    \n",
    "    accuracy = tf.metrics.accuracy(label_ids, predictions)\n",
    "    \n",
    "classificatoin_layer_vars = [output_weights, output_bias]\n",
    "global_step = tf.Variable(0)\n",
    "#train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss, var_list=classificatoin_layer_vars, global_step=global_step)\n",
    "train_op = optimization.create_optimizer(loss, init_lr=learning_rate, num_train_steps=num_train_steps, num_warmup_steps=1, use_tpu=False, tvars=classificatoin_layer_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = {}\n",
    "metrics['step'] = []\n",
    "metrics['train_loss'] = []\n",
    "metrics['eval_acc'] = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    sess.run(tf.initialize_local_variables())\n",
    "    bert_vars = [var for var in tf.global_variables() if var.name.startswith('bert')]\n",
    "    saver = tf.train.Saver(bert_vars)\n",
    "    saver.restore(sess, init_checkpoint)\n",
    "    \n",
    "    train_batch = sess.run(train_batch_iter)\n",
    "    eval_batch = sess.run(eval_batch_iter)\n",
    "    \n",
    "    for step in range(num_train_steps):\n",
    "        out = sess.run([train_op, loss, accuracy], feed_dict={handle: train_batch, dropout_keep_prob: 0.9})\n",
    "        train_loss = out[1]\n",
    "        \n",
    "        if step % 2 == 0:\n",
    "            eval_acc = evaluate(accuracy, {handle: eval_batch, dropout_keep_prob: 1.0}, sess, epoch_batch_num)\n",
    "            \n",
    "        metrics['train_loss'].append(train_loss)\n",
    "        metrics['eval_acc'].append(eval_acc)\n",
    "        metrics['step'].append(step)\n",
    "        \n",
    "        plt.scatter(metrics['step'], metrics['train_loss'], c='g')\n",
    "        plt.scatter(metrics['step'], metrics['eval_acc'], c='b')\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        \n",
    "        #metrics.to_csv('metrics/step_%d.csv'%(step))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, nan, nan]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics['train_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
